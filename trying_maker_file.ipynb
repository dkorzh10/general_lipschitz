{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "566e840a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jan 30 18:53:35 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla V100-SXM2-16GB           On  | 00000000:06:00.0 Off |                    0 |\n",
      "| N/A   39C    P0              60W / 300W |   1543MiB / 16384MiB |      0%   E. Process |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2-16GB           On  | 00000000:07:00.0 Off |                    0 |\n",
      "| N/A   39C    P0              49W / 300W |      3MiB / 16384MiB |      0%   E. Process |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-SXM2-16GB           On  | 00000000:0A:00.0 Off |                    0 |\n",
      "| N/A   40C    P0              42W / 300W |      3MiB / 16384MiB |      0%   E. Process |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-SXM2-16GB           On  | 00000000:0B:00.0 Off |                    0 |\n",
      "| N/A   43C    P0              73W / 300W |  10643MiB / 16384MiB |      0%   E. Process |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   4  Tesla V100-SXM2-16GB           On  | 00000000:85:00.0 Off |                    0 |\n",
      "| N/A   54C    P0             178W / 300W |  14687MiB / 16384MiB |     99%   E. Process |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   5  Tesla V100-SXM2-16GB           On  | 00000000:86:00.0 Off |                    0 |\n",
      "| N/A   64C    P0             292W / 300W |  13321MiB / 16384MiB |     62%   E. Process |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   6  Tesla V100-SXM2-16GB           On  | 00000000:89:00.0 Off |                    0 |\n",
      "| N/A   64C    P0             106W / 300W |  15319MiB / 16384MiB |    100%   E. Process |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   7  Tesla V100-SXM2-16GB           On  | 00000000:8A:00.0 Off |                    0 |\n",
      "| N/A   64C    P0             248W / 300W |   8613MiB / 16384MiB |     98%   E. Process |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc1155ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3], device='cuda:0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=\"1\"\n",
    "os.environ['CUDA_LAUNCH_BLOCKING']=\"1\"\n",
    "import torch\n",
    "\n",
    "torch.tensor([3]).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7ab7e48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.4451,  1.2140, -1.1644,  0.5476,  0.5005,  2.6480, -1.0846, -0.8021,\n",
       "         1.6652, -0.3085], device='cuda:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda')\n",
    "torch.randn(10).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a721675",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# sys.path.append('./..')\n",
    "# sys.path.append('./img2img')\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=\"1\"\n",
    "os.environ['CUDA_LAUNCH_BLOCKING']=\"1\"\n",
    "import json\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision\n",
    "from torchvision.models.resnet import resnet50\n",
    "import scipy\n",
    "\n",
    "from architectures import get_architecture\n",
    "from datasets_utils import get_dataset, DATASETS, get_num_classes, get_normalize_layer\n",
    "from src.numerical_methods import *\n",
    "from src.certification_utils import *\n",
    "from src.smoothing_and_attacks import *\n",
    "from src.utils import *\n",
    "\n",
    "\n",
    "\n",
    "NUM_IMAGES_FOR_TEST = 500\n",
    "\n",
    "sigma_b = None\n",
    "sigma_c = None\n",
    "sigma_tr = None\n",
    "sigma_gamma = None\n",
    "sigma_blur = None\n",
    "xi_tss = scipy.stats.norm.ppf\n",
    "\n",
    "rng = jax.random.PRNGKey(33)\n",
    "rng, key = jax.random.split(rng)\n",
    "ns = 10_000\n",
    "normal_samples = jax.random.normal(key, [100_000])\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Certify many examples')\n",
    "parser.add_argument(\"--dataset\",\n",
    "                    default='cifar10',choices=DATASETS, help=\"which dataset\")\n",
    "parser.add_argument(\"--base_classifier\", type=str,\n",
    "                    default=None,\n",
    "                    help=\"path to saved pytorch model of base classifier\")\n",
    "# parser.add_argument(\"sigma\", type=float, help=\"noise hyperparameter\")\n",
    "parser.add_argument(\"--outfile\", type=str,\n",
    "                    default='./logs/certify_results',\n",
    "                    help=\"output file\")\n",
    "parser.add_argument(\"--batch\", type=int, default=512, help=\"batch size\")\n",
    "parser.add_argument(\"--skip\", type=int, default=30\n",
    "                    , help=\"how many examples to skip\")\n",
    "parser.add_argument(\"--max\", type=int, default=-1, help=\"stop after this many examples\")\n",
    "parser.add_argument(\"--split\", choices=[\"train\", \"test\"], default=\"test\", help=\"train or test set\")\n",
    "parser.add_argument(\"--n0\", type=int, default=200)\n",
    "parser.add_argument(\"--maxn\", type=int, default=1000, help=\"number of samples to use\")\n",
    "parser.add_argument(\"--alpha\", type=float, default=1e-3, help=\"failure probability\")\n",
    "parser.add_argument('--corrupt',type=str,default=['none','gaussian_blur','motion_blur','zoom_blur','rotate','translate','contrast','pixelate','jpeg',][1],\n",
    "                    help=' The corruption type for training')\n",
    "parser.add_argument('--add_noise',type=float, default=0.0)\n",
    "parser.add_argument('--noise_dst',default=[\"none\",\"gaussian\",\"exp\",\"uniform\",\"folded_gaussian\"][2],type=str)\n",
    "parser.add_argument('--noise_sd', default=0.8, type=float,\n",
    "                    help=\"standard deviation of Gaussian noise for data augmentation\")\n",
    "parser.add_argument('--partial_min',default=0.0, type=float,\n",
    "                    help = \"Minimal of certify range\")\n",
    "parser.add_argument('--adaptive',default=True, type=bool,\n",
    "                    help = \"whether to stop certification procedure earlier\")\n",
    "parser.add_argument('--partial_max',default=1.0, type=float,\n",
    "                    help = \"Maximal of certify range\")\n",
    "parser.add_argument('--arch', type=str, default=[\"edsr\",\"unet\",\"runet\"][2])\n",
    "args = parser.parse_args([])\n",
    "\n",
    "\n",
    "def make_test_dataset(args):\n",
    "    test_dataset = get_dataset(args.dataset, \"test\")\n",
    "    pin_memory = (args.dataset == \"imagenet\")\n",
    "    np.random.seed(42)\n",
    "    idxes = np.random.choice(len(test_dataset), NUM_IMAGES_FOR_TEST, replace=False)\n",
    "    \n",
    "    ourdataset = make_our_dataset_v2(test_dataset, idxes)\n",
    "    ourdataloader = DataLoader(ourdataset, shuffle=False, batch_size=1,\n",
    "                         num_workers=6, pin_memory=False)\n",
    "    return ourdataset, ourdataloader\n",
    "\n",
    "\n",
    "def construct_bounds(ns, b_zero, x0, d, betas_list, type_of_transform, sigmas=[None, None, None, None, None]):\n",
    "    shape = [b.shape[0] for b in betas_list]\n",
    "    shape = tuple(shape)\n",
    "    betas = jnp.asarray(list(map(jnp.array, itertools.product(*betas_list))))\n",
    "#     sigma_b, sigma_c, sigma_tr, sigma_gamma, sigma_blur = sigmas\n",
    "#     gamma = construct_gamma(sigma_b=sigma_b, sigma_c=sigma_c, sigma_tr=sigma_tr, sigma_gamma=sigma_gamma, sigma_blur=sigma_blur)\n",
    "    gamma = construct_gamma(*sigmas)\n",
    "    bounds, p, g = compute_normed_bounds(compute_bound, x0, gamma, b_zero, betas, key, ns, d, type_of_transform)\n",
    "    x, xi = pxi_to_xi(p)\n",
    "#     for b in bounds[:1000]:\n",
    "#         plt.plot(b)\n",
    "#     plt.show()\n",
    "\n",
    "#     plt.plot(g)\n",
    "#     plt.show()\n",
    "\n",
    "#     plt.plot(p)\n",
    "#     plt.show()\n",
    "    z = csaps(betas_list, g.reshape(shape))\n",
    "    \n",
    "    hg = []\n",
    "\n",
    "    for beta in tqdm(betas):\n",
    "        hat_g = g_to_hat_g(z, beta, b_zero)\n",
    "        hg.append(hat_g)\n",
    "\n",
    "    hat_g = jnp.asarray(hg)\n",
    "\n",
    "    hatg_int = csaps(betas_list, hat_g.reshape(shape)) #\n",
    "    return xi, hatg_int\n",
    "\n",
    "\n",
    "\n",
    "def calculate_general(args):\n",
    "    n0 = args.n0\n",
    "    maxn = args.maxn\n",
    "    adaptive = False\n",
    "    alpha = args.alpha\n",
    "    \n",
    "    device = torch.device(args.device)\n",
    "    model = get_architecture(arch=args.arch, dataset=args.dataset, device=device)\n",
    "    checkpoint = torch.load(args.base_classifier, map_location=device)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "\n",
    "\n",
    "    \n",
    "    dataset, dataloader = make_test_dataset(args)\n",
    "    \n",
    "    base_classifier.to(device)\n",
    "    base_classifier.eval()\n",
    "\n",
    "    corruptor = Corruption(args, co_type=args.corrupt,add_noise=args.add_noise,noise_sd=args.noise_sd,distribution=args.noise_dst)\n",
    "\n",
    "    # create the smooothed classifier g\n",
    "    smoothed_classifier = TSmooth(base_classifier, None, corruptor, get_num_classes(args.dataset),args.noise_dst,args.noise_sd, args.add_noise)\n",
    "\n",
    "    # prepare output file\n",
    "    filename = args.outfile+'_'+args.dataset+'_'+args.corrupt+'_'+str(args.noise_sd) +\"_\" +str(args.partial_max)\n",
    "    f = open(filename+'_running', 'w')\n",
    "    print(\"idx\\tlabel\\tpredict\\tradius\\tgood\\tcorrect\\ttime\", file=f, flush=True)\n",
    "    print(\"idx\\tlabel\\tpredict\\tradius\\tgood\\tcorrect\\ttime\")\n",
    "\n",
    "    tot, tot_good, tot_correct = 0, 0, 0\n",
    "\n",
    "    # for gaussian smooth\n",
    "    attack_radius = args.partial_max\n",
    "    for i in tqdm(range(len(dataset))):\n",
    "        (x, label) = dataset[i]\n",
    "\n",
    "        before_time = time()\n",
    "        x = x.to(device)\n",
    "        prediction, radius = smoothed_classifier.certify(x, args.N0, args.N, args.alpha, args.batch)\n",
    "\n",
    "\n",
    "        correct = (prediction == label).item()\n",
    "        cond1 = radius * args.noise_sd > args.partial_max\n",
    "        good = (radius * args.noise_sd > args.partial_max)&correct\n",
    "\n",
    "        tot, tot_good, tot_correct = tot+1, tot_good+good, tot_correct+correct\n",
    "        after_time = time()\n",
    "        time_elapsed = str(datetime.timedelta(seconds=(after_time - before_time)))\n",
    "        print(\"{}\\t{}\\t{}\\t{:.5f}\\t{}\\t{}\\t{}\".format(i, label, prediction, radius, good, correct, time_elapsed), file=f, flush=True)\n",
    "        print(\"{}\\t{}\\t{}\\t{:.5f}\\t{}\\t{}\\t{}\".format(i, label, prediction, radius, good, correct, time_elapsed))\n",
    "\n",
    "    f.close()\n",
    "\n",
    "    print(\"Total {} Certified {} Certified Acc {} Test Acc {}\".format(tot, tot_good, tot_good/tot, tot_correct/tot))\n",
    "\n",
    "    f = open(filename+'_total_result', 'w')\n",
    "    print(\"Total {} Certified {} Certified Acc {} Test Acc {}\".format(tot, tot_good, tot_good/tot, tot_correct/tot), file=f, flush=True)\n",
    "    f.close()\n",
    "\n",
    "    \n",
    "@click.command()\n",
    "@click.argument(\"config_path\", type=click.Path(exists=True))\n",
    "def main(config_path):\n",
    "    with open(config_path, \"r\") as f:\n",
    "        config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "        \n",
    "    args.corrupt = config[\"corrupt\"]\n",
    "    args.noise_sd = config[\"noise_sd\"]\n",
    "    args.noise_dst = config[\"noise_dst\"]\n",
    "    args.partial_max = config[\"partial_max\"]\n",
    "    args.dataset = config[\"dataset\"]\n",
    "    args.base_classifier = config[\"base_classifier\"]\n",
    "    args.device = config[\"device\"]\n",
    "    args.arch = config[\"arch\"]\n",
    "    \n",
    "#     if config[\"gpu\"]:\n",
    "#         os.environ['CUDA_VISIBLE_DEVICES']=str(config[\"gpu\"])\n",
    "#         os.environ['CUDA_LAUNCH_BLOCKING']=\"1\"\n",
    "        \n",
    "\n",
    "\n",
    "    calculate_gsmooth(args)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19bf9d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md\t  dataset_cache\t\t requirements_old.txt\n",
      "__init__.py\t  datasets_utils.py\t results\n",
      "__pycache__\t  gsmooth\t\t src\n",
      "architectures.py  new_results\t\t train.py\n",
      "archs\t\t  new_results.tar.gz\t train_utils.py\n",
      "checkpoints\t  notebooks\t\t trying_maker_file.ipynb\n",
      "checkpoints.tar   requirements.txt\t tss_weights\n",
      "configs\t\t  requirements_full.txt  wandb\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c71626c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting python-box\n",
      "  Obtaining dependency information for python-box from https://files.pythonhosted.org/packages/88/cf/c75636ecfc9185630d6359fbb802b6a137a6cc763e0af6597a96b54bd343/python_box-7.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading python_box-7.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.8 kB)\n",
      "Downloading python_box-7.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: python-box\n",
      "Successfully installed python-box-7.1.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install python-box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ec96e6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from box import Box\n",
    "config_path = \"configs/cb/imagenet.yaml\"\n",
    "with open(config_path, \"r\") as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "03ddc521",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Box.from_yaml(filename=config_path, Loader=yaml.FullLoader) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4bab4163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(config.betas_estimation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4d831be9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box({'transform': 'cb', 'dimenshion': 2, 'dataset': 'imagenet', 'base_classifier': '../../checkpoints/brightness/checkpoint.pth.tar', 'device': 'cuda', 'arch': 'resnet50', 'gpu': 5, 'sigmas': {'sigma_b': 0.3, 'sigma_c': 0.3, 'sigma_tr': None, 'sigma_blur': None, 'sigma_gamma': None}, 'betas_estimation': {'beta0': {'left': 0.5, 'right': 1.5, 'db': 21}, 'beta1': {'left': -0.5, 'right': 0.5, 'db': 23}}, 'betas_certification': {'beta0': {'left': 1.4, 'right': 1.4, 'db': 35}, 'beta1': {'left': -0.4, 'right': 0.4, 'db': 41}}})"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724ce5aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
