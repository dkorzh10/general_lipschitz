{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ce60a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "# sys.path.append('./..')\n",
    "# sys.path.append('./img2img')\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=\"5\"\n",
    "os.environ['CUDA_LAUNCH_BLOCKING']=\"1\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "NUM_IMAGES_FOR_TEST = 500\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Certify many examples')\n",
    "parser.add_argument(\"--dataset\",\n",
    "                    default='cifar10',choices=DATASETS, help=\"which dataset\")\n",
    "parser.add_argument(\"--base_classifier\", type=str,\n",
    "                    default=None,\n",
    "                    help=\"path to saved pytorch model of base classifier\")\n",
    "# parser.add_argument(\"sigma\", type=float, help=\"noise hyperparameter\")\n",
    "parser.add_argument(\"--outfile\", type=str,\n",
    "                    default='./logs/certify_results',\n",
    "                    help=\"output file\")\n",
    "parser.add_argument(\"--batch\", type=int, default=512, help=\"batch size\")\n",
    "parser.add_argument(\"--skip\", type=int, default=30\n",
    "                    , help=\"how many examples to skip\")\n",
    "parser.add_argument(\"--max\", type=int, default=-1, help=\"stop after this many examples\")\n",
    "parser.add_argument(\"--split\", choices=[\"train\", \"test\"], default=\"test\", help=\"train or test set\")\n",
    "parser.add_argument(\"--N0\", type=int, default=100)\n",
    "parser.add_argument(\"--N\", type=int, default=1000, help=\"number of samples to use\")\n",
    "parser.add_argument(\"--alpha\", type=float, default=1e-3, help=\"failure probability\")\n",
    "parser.add_argument('--corrupt',type=str,default=['none','gaussian_blur','motion_blur','zoom_blur','rotate','translate','contrast','pixelate','jpeg',][1],\n",
    "                    help=' The corruption type for training')\n",
    "parser.add_argument('--add_noise',type=float, default=0.0)\n",
    "parser.add_argument('--noise_dst',default=[\"none\",\"gaussian\",\"exp\",\"uniform\",\"folded_gaussian\"][2],type=str)\n",
    "parser.add_argument('--noise_sd', default=0.8, type=float,\n",
    "                    help=\"standard deviation of Gaussian noise for data augmentation\")\n",
    "parser.add_argument('--partial_min',default=0.0, type=float,\n",
    "                    help = \"Minimal of certify range\")\n",
    "parser.add_argument('--partial_max',default=1.0, type=float,\n",
    "                    help = \"Maximal of certify range\")\n",
    "parser.add_argument('--arch', type=str, default=[\"edsr\",\"unet\",\"runet\"][2])\n",
    "args = parser.parse_args([])\n",
    "\n",
    "\n",
    "def make_test_dataset(args):\n",
    "    test_dataset = get_dataset(args.dataset, \"test\")\n",
    "    pin_memory = (args.dataset == \"imagenet\")\n",
    "    np.random.seed(42)\n",
    "    idxes = np.random.choice(len(test_dataset), NUM_IMAGES_FOR_TEST, replace=False)\n",
    "    \n",
    "    ourdataset = make_our_dataset_v2(test_dataset, idxes)\n",
    "    ourdataloader = DataLoader(ourdataset, shuffle=False, batch_size=1,\n",
    "                         num_workers=6, pin_memory=False)\n",
    "    return ourdataset, ourdataloader\n",
    "\n",
    "\n",
    "\n",
    "def calculate_general(args):\n",
    "    \n",
    "    device = torch.device(args.device)\n",
    "    model = get_architecture(arch=args.arch, dataset=args.dataset, device=device)\n",
    "    checkpoint = torch.load(args.base_classifier, map_location=device)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "\n",
    "    base_classifier = model\n",
    "    \n",
    "    dataset, _ = make_test_dataset(args)\n",
    "    \n",
    "    base_classifier.to(device)\n",
    "    base_classifier.eval()\n",
    "\n",
    "    corruptor = Corruption(args, co_type=args.corrupt,add_noise=args.add_noise,noise_sd=args.noise_sd,distribution=args.noise_dst)\n",
    "\n",
    "    # create the smooothed classifier g\n",
    "    smoothed_classifier = TSmooth(base_classifier, None, corruptor, get_num_classes(args.dataset),args.noise_dst,args.noise_sd, args.add_noise)\n",
    "\n",
    "    # prepare output file\n",
    "    filename = args.outfile+'_'+args.dataset+'_'+args.corrupt+'_'+str(args.noise_sd) +\"_\" +str(args.partial_max)\n",
    "    f = open(filename+'_running', 'w')\n",
    "    print(\"idx\\tlabel\\tpredict\\tradius\\tgood\\tcorrect\\ttime\", file=f, flush=True)\n",
    "    print(\"idx\\tlabel\\tpredict\\tradius\\tgood\\tcorrect\\ttime\")\n",
    "\n",
    "    tot, tot_good, tot_correct = 0, 0, 0\n",
    "\n",
    "    # for gaussian smooth\n",
    "    attack_radius = args.partial_max\n",
    "    for i in tqdm(range(len(dataset))):\n",
    "        (x, label) = dataset[i]\n",
    "\n",
    "        before_time = time()\n",
    "        x = x.to(device)\n",
    "        prediction, radius = smoothed_classifier.certify(x, args.N0, args.N, args.alpha, args.batch)\n",
    "\n",
    "\n",
    "        correct = (prediction == label).item()\n",
    "        cond1 = radius * args.noise_sd > args.partial_max\n",
    "        good = (radius * args.noise_sd > args.partial_max)&correct\n",
    "\n",
    "        tot, tot_good, tot_correct = tot+1, tot_good+good, tot_correct+correct\n",
    "        after_time = time()\n",
    "        time_elapsed = str(datetime.timedelta(seconds=(after_time - before_time)))\n",
    "        print(\"{}\\t{}\\t{}\\t{:.5f}\\t{}\\t{}\\t{}\".format(i, label, prediction, radius, good, correct, time_elapsed), file=f, flush=True)\n",
    "        print(\"{}\\t{}\\t{}\\t{:.5f}\\t{}\\t{}\\t{}\".format(i, label, prediction, radius, good, correct, time_elapsed))\n",
    "\n",
    "    f.close()\n",
    "\n",
    "    print(\"Total {} Certified {} Certified Acc {} Test Acc {}\".format(tot, tot_good, tot_good/tot, tot_correct/tot))\n",
    "\n",
    "    f = open(filename+'_total_result', 'w')\n",
    "    print(\"Total {} Certified {} Certified Acc {} Test Acc {}\".format(tot, tot_good, tot_good/tot, tot_correct/tot), file=f, flush=True)\n",
    "    f.close()\n",
    "\n",
    "    \n",
    "@click.command()\n",
    "@click.argument(\"config_path\", type=click.Path(exists=True))\n",
    "def main(config_path):\n",
    "    with open(config_path, \"r\") as f:\n",
    "        config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "        \n",
    "    args.corrupt = config[\"corrupt\"]\n",
    "    args.noise_sd = config[\"noise_sd\"]\n",
    "    args.noise_dst = config[\"noise_dst\"]\n",
    "    args.partial_max = config[\"partial_max\"]\n",
    "    args.dataset = config[\"dataset\"]\n",
    "    args.base_classifier = config[\"base_classifier\"]\n",
    "    args.device = config[\"device\"]\n",
    "    args.arch = config[\"arch\"]\n",
    "    \n",
    "#     if config[\"gpu\"]:\n",
    "#         os.environ['CUDA_VISIBLE_DEVICES']=str(config[\"gpu\"])\n",
    "#         os.environ['CUDA_LAUNCH_BLOCKING']=\"1\"\n",
    "        \n",
    "\n",
    "\n",
    "    calculate_gsmooth(args)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
